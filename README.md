# Data Platform Study

This repo is a personal study on Data Engineering / Analytics pipelines, and the tools that make them up.


## Modules
- datalake - A basic datalake built on MinIO 
- datalake-ingest - A python REST API which is used to ingest records into the datalake
- (todo) orchestration - A workflow orchestrator, schedules and executes data pipelines (probably going with airflow)
- (todo) compute-engine - A distributed compute engine, for processing large datasets. Apache spark or similar.
- (todo) workflows - A collection of data pipelines, which are orchestrated by the orchestration module
